---
author: admin
categories:
- Python
- 機械学習
date: 2017-10-01T03:56:19+00:00
dsq_thread_id:
- 6.182856e+09
excerpt: タイタニックで決定木、交差検証、グリッドサーチ
follow:
- follow
fullscreen_view:
- "n"
index:
- index
menu_view:
- "y"
page_layout:
- def
pdrp_attributionLocation:
- end
pvc_views:
- 427
side:
- "y"
tags:
- Kaggle
- scikit-learn
title: タイタニックで決定木、交差検証、グリッドサーチ(Python)
title_view:
- "y"
type: post
url: /archives/=6801
---

## はじめに {#-}

データサイエンティスト養成講座の第二回を受けてきました。

  * [即日満席のデータサイエンティスト養成講座―データサイエンティスト協会が5月と9月に開講：資格Zine（しかくジン）][1]

扱った内容は、

  * 決定木
  * クロスバリデーション
  * グリッドサーチ

講座では、Rを使うのだけれども、Pythonにもなれておきたいので、
  
講座の内容をPythonで復習しました。
  
ついでに、kaggleのタイタニック問題を決定木で解きました。

今回のコードは、githubにあげています。以下は、コードの抜粋です。

  * <https://nbviewer.jupyter.org/github/tsu-nera/kaggle/blob/master/titanic/decision_tree.ipynb>

## Pythonで決定木 {#python-}

Pythonで決定木を使うには、scikit-learnライブラリを使う。

<pre><code class="lang-python">from sklearn import tree
clf = tree.DecisionTreeClassifier(random_state=17)
clf.fit(X, y)
</code></pre>

簡単！

## クロスバリデーション with KFold {#-with-kfold}

決定木は、max_depthパラメータを大きくすればするほど精度が上がっていくが、汎化性能が下がっていく。なので、クロスバリデーションという方法を使って、過学習が起こっていないかチェックすることが重要になる。

<pre><code class="lang-python">from sklearn.model_selection import KFold
from sklearn import metrics
from sklearn.metrics import accuracy_score
K = 5
kf = KFold(n_splits=K, shuffle=True, random_state=17)

score_train_tmp = 0
score_test_tmp = 0

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    # 構築データでモデル構築
    clf.fit(X_train, y_train)

    # 構築データの予測値
    pred_train = clf.predict(X_train)

    # 構築データのaccuracy
    auccuracy = accuracy_score(pred_train, y_train)

    #構築データのaccuracyを足していく
    score_train_tmp+=auccuracy

    #検証データの予測値
    pred_test = clf.predict(X_test)

    #検証データのaccuracy
    auccuracy = accuracy_score(pred_test, y_test)

    #検証データのaccuracyを足していく
    score_test_tmp+=auccuracy
</code></pre>

    score_train_tmp/K
    0.82463676190176005
    
    score_test_tmp/K
    0.80247944259619608
    

構築データと検証データのスコアが近ければ、過学習が起こっていないと判断できる。これが乖離していると過学習が起こっているので、パラメータチューニングが必要。

## グリッドサーチ {#-}

最適なパラメータをしらみつぶしにパラメータを組み合わせて探索していく方法をグリッドサーチという。普通はfor文を回してパラメータを変えてスコアを見ることで調整していく。しかし、scikit-learnには、GridSearchCVというグリッドサーチをするための専用のクラスが用意されている。

これをつかえば、煩わしいfor文のネストを書かずとも、複数パラメータに対して探索をすくことができる。

調べたいパラメータをまずは辞書で定義する。

<pre><code class="lang-python">from sklearn.model_selection import GridSearchCV

# use a full grid over all parameters
param_grid = {"max_depth": [2,4,6,8,10],
              "max_features": [&#39;log2&#39;, &#39;sqrt&#39;,&#39;auto&#39;],
              "min_samples_split": [2, 3, 5],
              "min_samples_leaf": [1,5,8],
              "criterion": ["gini", "entropy"]}
</code></pre>

次に、GridSearchCVを読んで、グリッドサーチを実行する。

<pre><code class="lang-python">tree_grid = GridSearchCV(estimator=clf,
                 param_grid = param_grid,   
                 scoring="accuracy",  #metrics
                 cv = K,              #cross-validation
                 n_jobs =-1)          #number of core

tree_grid.fit(X,y) #fit

tree_grid_best = tree_grid.best_estimator_ #best estimator
print("Best Model Parameter: ",tree_grid.best_params_)
print("Best Model Score    : ",tree_grid.best_score_)
</code></pre>

    Best Model Parameter:  {&#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: 6, &#39;max_features&#39;: &#39;log2&#39;, &#39;min_samples_leaf&#39;: 8, &#39;min_samples_split&#39;: 2}
    Best Model Score    :  0.812570145903
    

便利だ。素晴らしい。

しかし、このパラメータチューニングした結果をサイトにて提出しても、大したスコアは出ない。これは、特徴量エンジニアリングがそもそもしょぼいという問題がある。

 [1]: https://shikakuzine.jp/article/detail/493