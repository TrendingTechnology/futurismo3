---
author: admin
categories:
- MOOC
- 機械学習
date: 2017-04-27T14:14:00+00:00
dsq_thread_id:
- 5.7647355e+09
follow:
- follow
fullscreen_view:
- "n"
index:
- index
menu_view:
- "y"
pvc_views:
- 1910
side:
- "y"
tags:
- DeepLearning
- TensorFlow
- Udacity
title: Udacity で Deep Learning Nanodegree Foundation を受講してる
title_view:
- "y"
type: post
url: /archives/=6285
---

Udacity で Deep Learning Nanodegree Foundation を受講してます。 -&gt;
追記: 受講が終わりました

-   [Deep Learning Nanodegree Foundation |
    Udacity](https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101)

MOOC を受けるのは、31 回目だけれども、 Udacity Nanodegree
は今回が始めて。なにしろ、学費が 599 ドル(= 6.5 万)というお値段。

1/3 が終わったので、少しずつまとめていこうと思う。
未完成だけれども、続きは、毎週更新する予定です。

![](./../img/2017-04-28-105746_820x538_scrot.png)

概要
====

Youtube Star の Siraj Raval
---------------------------

日本では知られていない、Deep Learning 界の Youtube Star, Siraj Raval が
Deep Learning の手法を教えてくれる。

動画がとにかくおもしろい。まずは動画紹介。

<iframe width="560" height="315" src="https://www.youtube.com/embed/vOppzHpvTiQ" frameborder="0" allowfullscreen></iframe>

授業の流れ
----------

授業は、Siraj さんと mat さんの動画を元に進められる。

-   Siraj's introductory video & One hour coding session
-   Additional lesson(s) from Mat & other Udacity experts

毎週 mat
先生の動画が公開されて、それを見てミニクイズやミニプロジェクトを解いていく。
それとは別に、siraj さんのライブコーディングセッションが youtube
で放送される。

### Projects

毎月一回、Project が assignment として課される。

-   Project 1 Your First Neural Network
-   Project 2 Image Classification
-   Project 3 Generate TV Scripts
-   Project 4 Translate a Language
-   Project 5 Generate Faces

どんな課題か見てみたい人は、github
の問題用リポジトリを参照するのがよい。

-   <https://github.com/udacity/deep-learning>

project の解答 を提出すると、Udacity のレビューアーにレビューされる
（ここが驚いた。高い学費を払っているだけあって、手厚いサポート）
解答内容が不十分だったり、間違っている場合は、リジェクトされて再提出が求められる。

わからない場合は、フォーラムを見たり、slack で議論したりする。 slack
には、なんと\#Japan のチャンネルがあり、日本語 OK.

受講者人数
----------

1 月に初めのコースが始まり、3 月に 2 回目のコースが始まった。自分は 3 月
から参加。

登録者数は 1 月が 5000 人くらい？3 月が 1500 人くらい（slack
の人数より）

日本人は、50 人くらい。

Syllabus
--------

1 月と 3 月では、シラバスの内容が少し違う。今後も feedback
を元に変わる可能性あり。

-   1 月のシラバス: [DL Handbook.key -
    Deep+Learning+Foundations+Student+Handbook.pdf](https://s3-us-west-2.amazonaws.com/udacity-email/Documents/Deep+Learning+Foundations+Student+Handbook.pdf?utm_medium=email&utm_campaign=2017-01-19_dlnd_jan27notice&utm_source=blueshift&utm_content=2017-01-19_dlnd_jan27notice&bsft_eid=1baa362f-396f-472d-b3f6-ff1eba51866f&bsft_clkid=8801d577-7317-4f4f-ab4f-44e0afda5d45&bsft_uid=7016ded3-d1a7-4679-b45b-8fc53d681ef4&bsft_mid=70af9439-0e61-45f8-8f28-19c6a94e2cb1)
-   3 月のシラバス: [Deep Learning Nanodegree Foundation Student
    Handbook](https://s3-us-west-2.amazonaws.com/udacity-email/Documents/Deep+Learning+Nanodegree+Foundation+Student+Handbook_1.pdf?utm_medium=email&utm_campaign=dlnd-first-day-welcome&utm_source=blueshift&utm_content=dlnd-first-day-email&bsft_eid=f11aeb32-5de9-43e1-836a-a606cd9b8693&bsft_clkid=e0345c11-8fbf-4352-acd4-8fd45523f370&bsft_uid=990ed18a-d329-4492-81e4-479917763057&bsft_mid=bd76381c-55b2-43a2-92e6-80cdea3568cb&bsft_txnid=f0279b6f-6088-4039-b886-66fcb3385911)

``` {.text}
Week 1: Introduction to Deep Learning
Week 2: Model Evaluation and Validation
Week 3: Graph computations
Week 4: Intro to TensorFlow
Week 5: Deep Neural Networks
Week 6: Convolutional Networks
Week 7: Recurrent Neural Networks
Week 8: Word Embeddings
Week 9: Using TensorBoard
Week 10: Text Generation
Week 11: Sequence to Sequence Generation
Week 12: Transfer Learning
Week 13: Reinforcement Learning
Week 14: Autoencoders
Week 15: Generative Adversarial Networks (GAN)
Week 16: Image Generation
```

扱う手法は、NN, CNN, RNN, GAN と,Deep Learning
の主要な手法をカバーしている。

扱うトピックは、 感情判定、画像識別、株価の予測、テキスト生成、
Word2Vec, 自然言語処理、音楽生成、チャットボット、
ゲームプレイ、画像生成 ...

難易度と学習時間
----------------

シラバスによると、8-12 時間の勉強時間の確保が必要とのこと。
自分の場合は、だいたい 10 時間くらい勉強すれば消化できた。

難易度なのだけれども、今のところは難しくなく、ついていくことが出来る。
複雑な数式もでてこないので、高校生だって受けることが出来ると思う。

CNN は、難しい部分は tensorflow に任せてしまい、 tensorflow
の使い方を学ぶ印象を受けた。

Siraj's Live Coding Session
---------------------------

Siraj さんのライブコーディングでは以下のトピックがあつかわれる。

-   Week 1 (3/29): Linear Regression
-   Week 2 (4/5): Tensorboard
-   Week 3 (4/12): Reinforcement Learning with Games
-   Week 4 (4/19): Image Compression
-   Week 5 (4/26): Visualizing Networks (GAN)
-   Week 6 (5/3): Generative Models (GAN)
-   Week 7 (5/10): Classification
-   Week 8 (5/17): Dimensionality Reduction
-   Week 9 (5/24): Data Visualization
-   Week 10 (5/31): Math terminology
-   Week 11 (6/7): Cloud Computing overview (AWS, google cloud, etc.)
-   Week 12 (6/14): Anomaly Detection
-   Week 13 (6/21): Stock Prediction
-   Week 14 (6/28): Video Generation
-   Week 15 (7/5): GANs for audio generation
-   Week 16 (7/12): GANs for video generation
-   Week 17 (7/19) : Probabilistic Programming

学習メモ
========

以下は、各回の概要をメモしたもの。参考までに。。。

1. Neural Network
=================

week1: Introduction to Deep Learning
------------------------------------

はじめに anaconda や 線形代数の基礎と numpy、 Jupyter Notebook
の使い方などが紹介される。

そのあと、ニューラルネットワーク。 パーセプトロンからはじまり、Gradient
Descent, Backpropagation が説明される。

input と output レイヤだけの初歩から説明されて、 次に hidden
レイヤが説明されるので、とてもわかりやすい。

-   数学: <https://www.youtube.com/watch?v=N4gDikiec8E>
-   ニューラルネットワーク:
    <https://www.youtube.com/watch?v=p69khggr1Jo&t=58s>

Project1: Your First Neural Network
-----------------------------------

ニューラルネットワークを組んで、自転車の貸し出し台数を予測する。 numpy
だけでニューラルネットを組む。

自分はゼロから作る Deep Learning を途中まで読んだのだけれども、
このプロジェクトのやろうとしていることは、この本と同じ。
よい復習にもなったし、逆にこの本を読んでいたから理解が助かった。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=fox10225fox-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=4873117585&linkId=d0c62bdea00896a95341429cf9cb6c62"></iframe>

Project1 ができなかったら、refund してこの講座を諦めようと思っていた。
なんとか提出できて、リジェクトもされなかったので、このまま受けることにした。

（Machine Learning Nanodegree を受けている Studyplus の友達は、 Project
の出来が悪いとリジェクトされて再提出を求められるといっていた）

2. Convolutional Neural Network
===============================

week2: Graph Computations
-------------------------

TensorFlow の基礎となる Graph Computations を学び、 MiniFlow という
Tensorflow のミニバージョンを自作する。 といっても、これは week1 の復習
Quiz のようなもの。 また、手取り足取りの説明なので、すごく簡単。

またこの週では、データの前処理, モデルの評価や Validation
にも触れられる。

モデルの評価は、coursera ML でやったものと同じ。

-   データ前処理: <https://www.youtube.com/watch?v=koiTTim4M-s>

week3: Sentiment Analysis
-------------------------

センチメント分析がテーマ。

Andrew Trask
さんが登場し、ニューラルネットワークを利用して、センチメント分析を実施する。
この講義の目的は、いかにしてニューラルネットワークの精度を向上させるかと学習を高速化させるか。

はじめは、精度が 65%くらいしかないのだが、
あの手この手の工夫をすることで 95%以上にまでもっていく。
さらには学習の速度もはじめにくらべると爆速にもっていく。

チューニングでこれほど差がでるものかと驚いた。

また、この週では、TFLearn というライブラリが紹介される。
これをつかうと、ニューラルネットがシンプルに数行で構築できる。
バックプロパゲーションとか頑張ったのはなんだったんだよ！と思うほど、驚く。

-   [TFLearn で手書き文字認識(MNIST)を試してみた |
    Futurismo](https://futurismo.biz/archives/6222)

-   <https://www.youtube.com/watch?v=si8zZHkufRY>

week4: Intro to TensorFlow
--------------------------

TensorFlow の登場。やっと 4 週目にしてでてきた感がある。

TensorFlow の基礎文法をまなび、基本的な 2 層のニューラルネットを組む。
また、ロジスティック回帰について学ぶ。

この週は、今までで一番楽な週だった。

week5: Deep Neural Networks
---------------------------

Google AWS で GPU をつかう方法が示される。 この DLND
をとっている生徒は、100 ドルの無料クーボンがもらえるのだ。 これで AWS で
GPU を使って計算を高速化できる。また、FloydHub も紹介される。

といっても自分は別の用途で AWS をガンガン使ってしまったのでピンチ。

<blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">Udacity からもらった AWS 使用料 100 ドル分のクレジット、fast.ai の課題やるのに 20 ドル分つかってしまった！！</p>&mdash; tsu-nera@勉強垢 (@tsu_nera_s) <a href="https://twitter.com/tsu_nera_s/status/857490236099579904">2017 年 4 月 27 日</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

TenosorFlow で前回は、2 層のニューラルネットワークだったが、 それを 3
層のニューラルネットワークにする。

と同時に、オーバーフィッティングを防ぐ方法として、 正則化と Dropout
の手法が紹介される。

-   <https://www.youtube.com/watch?v=tTWOgPDJN9Q>

week6: Convolutional Networks
-----------------------------

Convolution Networks の説明。 畳み込みとプーリングの説明があったあと、
tensorflow でどう実装していくかが解説される

重みやバイアスの初期化方法についても言及される。

-   <https://www.youtube.com/watch?v=cAICT4Al5Ow>

Project2 Image Classification
-----------------------------

CIFAR10 の画像データを CNN で分類するというプロジェクト。

ネットワークは、week6
で与えられたコードを少し工夫すれば構築できるけれども、
ネットワークのパラメータを調整して精度をだすことに苦戦した。

最終的には、67% の精度がでた。合格ラインは 50% と低めなので、いい感じ。

3. Recurrent Neural Network
===========================

week7: Recurrent Neural Network
-------------------------------

Recurrent Neural Network の説明。
といっても、簡素な説明なので、ほとんどわからなかった！
参考リンクを示されてここ読んでおいてね、ということだった。

-   [Understanding LSTM Networks -- colah's
    blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

実践的な演習として、アンナ・カレーニナの小説を元に、文章を生成するものが
与えられる。TensorFlow を使って、LSTM を実装するのだが、
これが答えも一緒に示されるので、結構簡単に実装出来てしまう。

理論はまったくわからないが、実装出来てしまうので、これでいいのか？？

別枠として、LSTM で株の予想をしようという Siraj さんのビデオがある。

-   <https://www.youtube.com/watch?v=ftMq5ps503w>

week8: Word Embeddings
----------------------

Word Embeddings がテーマということで、Skip-gram モデルの word2vec
を自前で実装するというもの。

例のごとく、サンプルコードが与えられて、穴埋めしていく形で進められる。

-   <https://github.com/udacity/deep-learning/tree/master/embeddings>

論文やブログのリンクがはられて、読んでおいてねとのこと。外部リンクを読むことが前提みたい。

-   [Word2Vec Tutorial - The Skip-Gram Model · Chris
    McCormick](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)

この日本語記事がイラスト付きでとてもわかりやすかった。大感謝！！

-   [絵で理解する Word2vec の仕組み -
    Qiita](https://qiita.com/Hironsan/items/11b388575a058dc8a46a)

text8 という英語のテキストデータを学習する。
ニューラルネットの仕組みは簡単だったが、前処理が難しくて理解度がうすい。

-   SubSampling
-   Negative sampling

この Word2Vec を利用して、自分の Twitter アカウントを分析してみた。

-   [Word2Vec(skip-gram)で自分の twitter アカウントのツィート分析した |
    Futurismo](https://futurismo.biz/archives/6427)

Siraj さんのビデオは Style Transfer について。

-   <https://www.youtube.com/watch?v=Oex0eWoU7AQ>

これは、CADL で以前勉強していたので、深くは調べなかった。

![](./../img/miro_chaplin.gif)

FloydHub
創立者たちとのインタビュー動画もボーナスとしてあった。なんか、Udacity は
FloydHub 推奨しているみたい。

week9: Using TensorBoard
------------------------

TensorBorad を使う方法について。

TensorBoard は精度や Loss を可視化するのに便利だと思っていた。
今まで、闇雲にハイパーパラメータを探していたのだけれども、TensorBoard
を使って探す方法を学んだ。

Keras でも TensorBoard は使えるみたい。

-   [ハイパーパラメータは可視化して決めよう！Keras で TensorBorad を使う
    | Futurismo](https://futurismo.biz/archives/6445)

Siraj さんの動画は、Music
Generation(音楽生成)。とても興味があるトピック。待ってました\^-\^

-   <https://www.youtube.com/watch?v=4DMm5Lhey1U>

LSTM で音楽を学習させてみようということなのだけれども、
動画はよくわからなかった。しかし、ここで諦めてはいけない。 Siraj
さんの動画は大抵数行のコードと大量の参照リンクなので自学自習が必要なのだ。

いろいろディープラーニングと音楽生成の関係を調べていくうちに、 char-rnn
で音楽生成をしている事例がたくさん見つかった。なので、私もやってみた！

-   [ディープラーニング(char-rnn)でバッハの音楽を生成してみた |
    Futurismo](https://futurismo.biz/archives/6454)

week10: Text Generation
-----------------------

テキスト生成。week8 では、文字ベースの文章生成をあつかったけれども、
ここでは単語ベースの文章生成。

この週では、Project3 が課せられたので、まずは準備として、 RNN による
センチメント分析をおこなった。 複数の input に対して一つの output
を出力する RNN.

センチメント分析は week3 で扱ったのだが、それを RNN
という別の角度から再実施する。

Project3 Generate TV Scripts
----------------------------

有名テレビアニメ、ザ・シンプソンズのテレビスクリプトを学習し、 word
ベースの RNN を使ってテレビスクリプトを生成しようという Project.

いつもながら、プロジェクトは演習のコピペでできてしまうので、簡単。

week11: Sequence to Sequence/Chatbot QA System with voice
---------------------------------------------------------

複数の Input に対して、複数の Output を返す RNN のアーキテクチャの紹介。

この週は、わけがわからなかったな。はじめての挫折。

week12: Transfer Learning
-------------------------

転移学習。このトピックは大事。Kaggle
などのデータ分析コンペで有用な手法。

この週の課題は、外部のリポジトリを使って tensorflow で vgg16
を使って、花の分類をする。

-   <https://github.com/machrisaa/tensorflow-vgg>

私は、fast.ai
でこの転移学習についてたくさん学んでいたので、この週では学ぶことは少なかった。
逆に言えば、fast.ai の lesson1 をみることをつよくオススメしたい。lesson1
には日本語字幕もある!

-   <https://course.fast.ai/lessons/lesson1.html>

week13: Reinforcement Learning
------------------------------

強化学習。ここでは、Deep Q-Network が紹介される。
強化学習はそれ自体大きな一つの分野なので、一週間で紹介するには無理があるのではと思った。

このあたりから、自分の興味は、Deep Learning から強化学習に移りはじめる。
なので、GAN はあまり理解できていない。

演習問題では、OpenAI Gym の CartPole 問題を Tensorflow を使って DQN
でとく。 かなりいい結果がでて驚く。

これを参考に、Keras や Numpy
で再実装を実施してみたのだが、思うように結果が出なかった。

-   [CartPole 問題に DQN(numpy only)で挑戦したけど解けなかった |
    Futurismo](https://futurismo.biz/archives/6612)

Project4 Translate a Language
-----------------------------

機械翻訳。英語からフランス語への翻訳を実施する。

難しそうだけれども、いつも通りスケルトンのコードが与えられて、week11
を参考にして穴埋めしていく。

フランス語がわからないので、翻訳結果が正しいのかはわからないけれども、一応できた。

この課題を参考に、チャットボットをつくってみたのだけれども、

&lt;PAD&gt;&lt;PAD&gt;&lt;PAD&gt;&lt;PAD&gt;&lt;PAD&gt;&lt;PAD&gt;...

しか応答してくれない。
なにが悪いのかもあまり理解していないので、追いきれない。
チャットボットは後味が悪いけれども、ここまでにする。

-   <https://github.com/tsu-nera/chatbot-tf>

4. Generative Adversarial Network
=================================

week14: Autoencoders
--------------------

自己符号化器。

week15: Generative Adversarial Networks
---------------------------------------

ここから GAN が始まる。

Deep Learning Book の著者, GAN の提唱者、 Ian GoodFellow
さんが登場し、GAN について解説してくれる。若い！

MNIST を GAN
で生成することをする。すごいけど、仕組みが複雑で難しい。。。

week16: Image Generation
------------------------

前回に引き続いて、GAN. Deep Convolution GAN(DCGAN) が説明される。

CNN でつかった Convolution の関数が出てくるところ意外は、MNIST の GAN
と同じ。 ただし、プーリング層はでてこない。

また、Batch Normalization が登場する。これが GAN の性能をよくする。

看板の数字？？を題材にして、DCGAN をする演習がある。

Project5 Generate Faces
-----------------------

最終課題は、DCGAN で MNIST と CelebA
のデータセットを使って、画像生成をすること。

GAN をあまり理解していないのだが、DCGAN の回の Jupyter Notebook
のコピペでなんとか乗り切った。

まとめ
======

この NanoDegree は超初心者向け、簡単
------------------------------------

広範囲をカバーして難しそうなイメージを持っていたけれども、実際やってみると、難しい数式はでてこない。

講義は Jupyter Notebook で手取り足取りな丁寧さでかかれている。

Project は Lecture の Jupyter Notebook のコピペでクリアできたり、簡単。

ひとによっては、この難易度では物足りないのではないかとすら思う。自分にはちょうど良いレベル。

こんな自分でもできました
------------------------

はじめ自分は DeepLearning はとても難しいものだと思っていた。

なので、こういうステップを踏んで入門しようと思っていた。

1.  大学 1,2 年の数学を復習
2.  機械学習を勉強する
3.  Deep Learning を勉強する

しかし、いざ Deep Learning の世界に踏み込んでみると、
数学すら怪しい自分でも、なんとかついていくことができた。

普通に CNN をバリバリ実装して kaggle にチャレンジとかできている。

-   [TensorFlow で学ぶディープラーニング入門を読んだ。Kaggle
    で実践してみた。 | Futurismo](https://futurismo.biz/archives/6274)

fast.ai の理念
--------------

現在、Udacity DLND の裏で fast.ai が提供する MOOC, Practical Deep
Learning for Coders というものを受けているのだけれども、 この MOOC
の理念が素晴らしいので引用したい。

-   [Lesson 1 Notes - Deep Learning Course
    Wiki](https://wiki.fast.ai/index.php/Lesson_1_Notes)

> The purpose of this course is to make deep learning accessible to
> those individuals who may or may not possess a strong background in
> machine learning or mathematics.
>
> We strongly believe that deep learning will be transformative in any
> application; as such, this course is designed for individuals who
> possess a background in computer programming and would like to apply
> these techniques to their domain of expertise.

つまり、Deep Learning は 数学者や物理学者のためのものでなくて、 CS
のバックグラウンドを持つ全ての人に開かれるべきだという主張だ。

なんか、fast.ai の宣伝になってしまったが、Udacity の DLND
はそういう部分がある。 理論は抑えるものの、より実践的に tensorflow
を利用して現実につかっていくかにフォーカスしているように思える。

Deep Learning で世界をハック
----------------------------

恐れずに、Deep Learning
に飛び込んでみよう。きっと面白いハッキングができるようになるはずだ。

Udacity のコースは、面白いハッキングの材料を提供してくれるはずだ。

<p style="font-size:32px">以上、Happy Hacking!!</p>
